# The Digger

A tool for finding and listening to tracks played by your favorite DJs on MixesDB.

## Features

- Search for any DJ/artist on MixesDB
- View all tracks they've played in their sets
- Listen to tracks directly in the app (audio-only, starting at 2 minutes)
- Export tracklists as PDF for offline use
- Built-in YouTube search for finding exact tracks
- Discogs integration with label discography search and release details
- Discogs button in release modals for quick access to original release pages
- Minimal, clean interface with responsive design
- Fast caching system for improved performance
- Automatic rate limiting to prevent being blocked
- Background job processing for handling heavy operations

## ðŸ”„ New Features and Improvements

### ðŸ”‰ YouTube Audio Proxy

The application now includes a YouTube audio proxy feature that allows playback of tracks that have embedding restrictions. When a track can't be embedded in the player, the app will automatically try to extract the audio directly.

### ðŸ“‹ Combined Setup Process

The setup process has been simplified with a single script that works for both development and production environments:

```bash
# For development setup
./setup.sh

# For production setup
./setup.sh -p
```

### ðŸš€ Deployment Improvements

- Worker process now uses worker.py which is compatible with the Procfile
- Fixed cache management to improve performance with large track lists
- PDF generation has been improved to properly include all tracks

## Running the App

### Quick Start

1. Make sure you have Python 3.x installed
2. Clone this repository

```bash
git clone https://github.com/yourusername/the-digger.git
cd the-digger
```

3. Set up a virtual environment (optional but recommended)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

4. Install dependencies

```bash
pip install -r requirements.txt
```

5. Start Redis (required for background job processing)
   Make sure Redis is installed and running locally on the default port (6379)
   or set the REDIS_URL environment variable to point to your Redis instance.

6. Run the application (choose one option)

#### Option A: Simple mode (all-in-one)

```bash
# Using the shell script (recommended for beginners)
./run-app.sh
```

#### Option B: Advanced mode (separate backend and worker)

For better performance and handling of long-running jobs, run the app using separate processes:

Terminal 1 - Start the Flask application:

```bash
./run-app.sh
```

Terminal 2 - Start the worker process:

```bash
python worker.py
```

With this setup, the Flask app handles web requests while the worker processes background jobs separately. This prevents long-running operations from blocking the web interface.

The app will automatically:

- Start the server
- Open your browser to http://localhost:8080

### Development Options

```bash
# Run with a different port
./run-app.sh -p 5000

# Run in debug mode
./run-app.sh -d

# Check dependencies
./check-dependencies.sh

# Run worker with custom Redis URL
REDIS_URL=redis://custom-host:6379 python worker_simple.py
```

## Environment Variables

The application can be configured using environment variables in a `.env` file:

### Production Configuration (Railway)
```bash
# Flask configuration
FLASK_DEBUG=0                    # Debug mode disabled in production
FLASK_HOST=0.0.0.0              # Bind to all interfaces
FLASK_PORT=8080                 # Default Railway port

# Redis configuration (Required for background jobs)
REDIS_URL=redis://default:password@redis.railway.internal:6379  # Auto-generated by Railway Redis service

# Cache configuration
CACHE_TTL=86400                 # Cache TTL in seconds (24 hours)
CACHE_EXPIRY=86400              # Request cache expiry (24 hours)

# Scraper performance settings
REQUEST_TIMEOUT=30              # HTTP request timeout (increased for stability)
MAX_RETRIES=5                   # Number of retry attempts (increased for reliability)
RETRY_DELAY=2                   # Seconds between retries
MAX_FETCH_LIMIT=300             # Maximum tracks to fetch per artist
MAX_PAGINATION_PAGES=8          # Maximum category pages to scrape
RATE_LIMIT_RPM=30               # Rate limiting (requests per minute)

# API configurations
YOUTUBE_USER_AGENT="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"

# Discogs API (Optional - for label discography features)
DISCOGS_TOKEN=your_discogs_token          # Get from https://www.discogs.com/settings/developers
DISCOGS_USER_AGENT="TheDigger/1.0 +https://github.com/Moodyw03/thedigger25"
```

### Development Configuration
```bash
# Flask configuration
FLASK_DEBUG=1                   # Debug mode enabled for development
FLASK_HOST=127.0.0.1           # Localhost only
FLASK_PORT=8080

# Redis configuration
REDIS_URL=redis://localhost:6379  # Local Redis instance

# Reduced limits for development
MAX_FETCH_LIMIT=100             # Smaller datasets for faster testing
MAX_PAGINATION_PAGES=5          # Fewer pages to scrape
CACHE_EXPIRY=3600               # 1 hour cache for development
RATE_LIMIT_RPM=45               # Higher rate limit for development
```

## ðŸš€ Deployment to Railway

This application is production-ready and deployed on Railway with Redis Queue support.

### Current Deployment
- **Live URL**: https://thedigger20.up.railway.app
- **Status**: âœ… Fully operational with background job processing
- **Redis**: Configured with Railway Redis service for queue management

### Deployment Steps

1. **Create Railway Project**
   ```bash
   # Sign up at railway.app
   # Create new project from GitHub repo
   ```

2. **Add Redis Service**
   ```bash
   # In Railway dashboard:
   # - Click "Add Service" â†’ "Database" â†’ "Redis"
   # - Copy the generated REDIS_URL
   ```

3. **Configure Environment Variables**
   In Railway service settings â†’ Variables tab:
   ```bash
   REDIS_URL=redis://default:password@redis.railway.internal:6379  # From Redis service
   FLASK_DEBUG=0
   FLASK_HOST=0.0.0.0
   FLASK_PORT=8080
   REQUEST_TIMEOUT=30
   MAX_RETRIES=5
   CACHE_TTL=86400
   # Optional: Add DISCOGS_TOKEN for label features
   ```

4. **Deploy Configuration**
   - Railway automatically detects `Procfile` and `requirements.txt`
   - Both web and worker processes start automatically
   - Auto-deployment on GitHub pushes

### Production Features
- âœ… **Horizontal Scaling**: Web + Worker process separation
- âœ… **Background Jobs**: Redis Queue with 1-hour timeout
- âœ… **Caching**: Multi-level Redis + in-memory caching
- âœ… **Rate Limiting**: 30 RPM with exponential backoff
- âœ… **Error Recovery**: Retry logic with circuit breakers
- âœ… **Real-time Monitoring**: Job status and progress tracking

### Security Configuration
- âœ… **Debug Mode**: Disabled in production
- âœ… **CORS**: Configured for cross-origin requests
- âœ… **Environment Variables**: Sensitive data in Railway variables
- âœ… **API Tokens**: Discogs token secured in environment
- âœ… **HTTPS**: Enforced by Railway edge servers

## Advanced Usage

### Direct PDF Generation

You can generate PDFs directly by navigating to:

```
http://localhost:8080/direct_pdf_download?artist_name=Ben%20UFO
```

### API Endpoints

The application provides a comprehensive REST API for music data processing:

#### Core Search Endpoints
- `POST /search` - Start background job for DJ tracklist search (recommended)
- `GET /job/<job_id>/status` - Get real-time job status and progress
- `GET /job/<job_id>/result` - Retrieve completed job results
- `POST /clear_cache` - Clear cached results for specific artist (admin)

#### Legacy/Direct Endpoints  
- `GET /api/list?artist_name=<name>` - Synchronous search (may timeout)
- `GET /search_video?query=<track>` - YouTube video search
- `GET /start_pdf_job?artist_name=<name>` - Background PDF generation
- `GET /get_pdf/<job_id>` - Download generated PDF

#### Discogs Integration
- `GET /discogs/search_label?label_name=<name>` - Search record labels
- `GET /discogs/label/<id>/releases` - Get label discography
- `GET /discogs/release/<id>` - Get detailed release information

#### Example Usage
```bash
# Start background search
curl -X POST https://thedigger20.up.railway.app/search \
  -d "artist_name=Eddie Richards"

# Check job status  
curl https://thedigger20.up.railway.app/job/<job_id>/status

# Get results
curl https://thedigger20.up.railway.app/job/<job_id>/result
```

## How It Works

1. The app scrapes DJ tracklists from [MixesDB](https://www.mixesdb.com/)
2. Background processing:
   - For large requests, the app uses a Redis queue and worker process
   - The web interface remains responsive while scraping happens in the background
   - Real-time progress updates are shown to the user
3. When you click Play, it searches YouTube for the track and plays the audio
4. For better listening experience, playback starts at 2 minutes into each track
5. If you want to view the full YouTube video, click the YouTube icon next to the player
6. PDF generation also happens in the background to prevent timeouts

## Technology Stack

### Backend Infrastructure
- **Framework**: Python 3.x, Flask 3.0.2
- **Queue System**: Redis 6.4.0, RQ (Redis Queue) 2.4.1
- **Worker Process**: Python RQ SimpleWorker with job persistence
- **Database**: Redis for caching and job queue management

### Data Processing Pipeline  
- **Web Scraping**: BeautifulSoup 4.13.4, requests 2.31.0
- **Data Validation**: Custom regex normalization and cleaning
- **Rate Limiting**: Configurable RPM limits with exponential backoff
- **PDF Generation**: ReportLab 4.3.1 for tracklist exports

### Frontend & APIs
- **UI**: Responsive HTML5, CSS3, vanilla JavaScript
- **Audio Playback**: YouTube embed API (audio-only mode)
- **External APIs**: MixesDB.com scraping, Discogs API, YouTube search
- **Real-time Updates**: AJAX polling for job status

### Production Deployment
- **Platform**: Railway cloud platform
- **Process Management**: Procfile-based (web + worker)
- **Security**: HTTPS, environment variable management
- **Monitoring**: Structured logging, error tracking

## ðŸ”’ Security & Best Practices

### Production Security
- âœ… **Environment Variables**: All sensitive data stored in Railway environment variables
- âœ… **Debug Mode**: Disabled in production (`FLASK_DEBUG=0`)
- âœ… **HTTPS**: Enforced by Railway edge servers
- âœ… **CORS**: Properly configured for cross-origin requests
- âœ… **Rate Limiting**: Prevents abuse with 30 RPM default limit
- âœ… **Input Validation**: All user inputs sanitized and validated
- âœ… **Error Handling**: Graceful error handling without sensitive data exposure

### API Security
- âœ… **No Authentication Required**: Public API for music data (by design)
- âœ… **Rate Limiting**: Built-in protection against spam/abuse
- âœ… **Request Validation**: All parameters validated and sanitized
- âœ… **Timeout Protection**: Configurable timeouts prevent resource exhaustion
- âœ… **Cache Security**: TTL-based cache invalidation

### External API Management
- âœ… **Discogs Token**: Secured in environment variables
- âœ… **User Agents**: Proper identification for external services
- âœ… **Respectful Scraping**: Rate limits respect target server resources

### Data Privacy
- âœ… **No User Data**: Application doesn't collect personal information
- âœ… **No Persistent Storage**: Only caches music metadata temporarily
- âœ… **Public Data Only**: Sources only publicly available information

## Development

### Contributing
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Ensure security best practices
5. Submit a pull request

### Security Guidelines
- Never commit API tokens or credentials
- Use environment variables for all configuration
- Test rate limiting and error handling
- Follow OWASP security practices

## License

This project is open source and available under the MIT License.
